{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56483e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f27d4ed",
   "metadata": {},
   "source": [
    "# How to fine-tune a GPT-3 model for specific prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b56a7b0",
   "metadata": {},
   "source": [
    "I'm constantly looking for ways to automate the work with support requests. An idea has been to fine-tune a GPT-3 model to answer common support-related questions.\n",
    "\n",
    "**Here's how you can fine-tune a GPT-3 model with Python with your own data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f831ab",
   "metadata": {},
   "source": [
    "In this walkthrough, we'll fine-tune a GPT-3 model to answer common support-related questions.\n",
    "\n",
    "Detailed step-by-step intructions for this repo in this blog post: https://norahsakal.com/blog/fine-tune-gpt3-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b102018b",
   "metadata": {},
   "source": [
    ">### Disclaimer\n",
    ">This guide walks you through fine-tuning a GPT-3 model in Python, shown in a Jupyter notebook.\n",
    ">If you're looking for the steps of fine-tuning right in a terminal, [OpenAI has a great guide for fine-tuning in your terminal](https://beta.openai.com/docs/guides/fine-tuning \"fine-tuning in terminal\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f669e",
   "metadata": {},
   "source": [
    "# Define OpenAI API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaff120",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key =\"YOUR_OPENAI_API_KEY\"\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f08dd7",
   "metadata": {},
   "source": [
    "# Create training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569f0c1f",
   "metadata": {},
   "source": [
    "Make sure to end each `prompt` with a suffix. According to the [OpenAI API reference](https://beta.openai.com/docs/guides/fine-tuning \"fine-tuning reference\"), you can use ` ->`.\n",
    "\n",
    "Also, make sure to end each `completion` with a suffix as well; I'm using `.\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5904b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = [{\n",
    "    \"prompt\": \"Prompt ->\",\n",
    "    \"completion\": \" Ideal answer.\\n\"\n",
    "},{\n",
    "    \"prompt\":\"Prompt ->\",\n",
    "    \"completion\": \" Ideal answer.\\n\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10cb45e",
   "metadata": {},
   "source": [
    "# Save dict as JSONL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ed465",
   "metadata": {},
   "source": [
    "Training data need to be a JSONL document.\n",
    "JSONL file is a newline-delimited JSON file.\n",
    "More info about JSONL: https://jsonlines.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4bc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"training_data.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as outfile:\n",
    "    for entry in data_file:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf169e",
   "metadata": {},
   "source": [
    "# Check JSONL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fe452",
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f training_data.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923b02a",
   "metadata": {},
   "source": [
    "# Upload file to your OpenAI account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_response = openai.File.create(\n",
    "  file=open(file_name, \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "upload_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb4254",
   "metadata": {},
   "source": [
    "# Save file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93469f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = upload_response.id\n",
    "file_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1007a6",
   "metadata": {},
   "source": [
    "# Fine-tune a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e2da9b",
   "metadata": {},
   "source": [
    "The default model is **Curie**. \n",
    "\n",
    "If you'd like to use **DaVinci** instead, then add it as a base model to fine-tune:\n",
    "\n",
    "```openai.FineTune.create(training_file=file_id, model=\"davinci\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_response = openai.FineTune.create(training_file=file_id)\n",
    "fine_tune_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059b2b3",
   "metadata": {},
   "source": [
    "# Check latest fine-tuning event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_response.events[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e846ed",
   "metadata": {},
   "source": [
    "# Save fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = fine_tune_response.fine_tuned_model\n",
    "fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601df11",
   "metadata": {},
   "source": [
    "# Test the new model on a new prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654268c",
   "metadata": {},
   "source": [
    "Remember to end the prompt with the same suffix as we used in the training data; ` ->`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cfb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = \"NEW PROMPT ->\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee69cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt,\n",
    "  max_tokens=10, # Change amount of tokens for longer completion\n",
    "  temperature=0\n",
    ")\n",
    "answer['choices'][0]['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
